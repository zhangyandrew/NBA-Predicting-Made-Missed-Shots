# LOAD PACKAGES

setwd('set/approp/wd')

install.packages('dplyr')
install.packages('ggplot2')
install.packages("tree")
install.packages("randomForest")
install.packages("ISLR")
install.packages('e1071')

# Aggregate/Prepare
library(dplyr)
shots <- read.csv("shot_logs1.csv")

# Separating and selecting which attributes to use
agg_shots <- data.frame(Location=shots[,3], Shot_Number=shots[,6], Period=shots[,7], Shot_Clock=shots[,9], Dribbles=shots[,10], Touch_Time=shots[,11], Shot_Distance=shots[,12], Pts_Type=shots[,13], Shot_Result=shots[,14], Close_Def_Dist=shots[,17], Player_Name=shots[,20])

# Filtering which players to include in the dataset
comp_agg_shots <- filter(agg_shots, Player_Name == c('kobe bryant', 'lebron james', 'stephen curry', 'kyrie irving', 'anthony davis', 'russell westbrook', 'deandre jordan'))

head(agg_shots)
head(comp_agg_shots)
head(shots)
```

# Preprocessing
attach(comp_agg_shots)
summary(comp_agg_shots)
sapply(comp_agg_shots, mean)
sapply(comp_agg_shots, sd)

str(comp_agg_shots)
# Must convert categoricals into numericals

#1: Away, 2: Home
comp_agg_shots$Location = as.numeric(comp_agg_shots$Location)

#1: Made, 2: Missed
comp_agg_shots$Shot_Result = as.numeric(comp_agg_shots$Shot_Result)

#159: Kobe Bryant, 248: Stephen Curry 
#20: Anthony Davis, 167: Kyrie Irving 
#172: Lebron James, 237: Russell Westbrook 
#67: Deandre Jordan
#Sorted alphabetically by first name
comp_agg_shots$Player_Name = as.numeric(comp_agg_shots$Player_Name)

comp_agg_shots[is.na(comp_agg_shots)] <- 0

str(comp_agg_shots)

smp_size <- floor(0.75 * nrow(comp_agg_shots))

set.seed(123)
train_ind <- sample(seq(nrow(comp_agg_shots)), size = smp_size)

# Separate train and test set
train <- comp_agg_shots[train_ind, ]
test <- comp_agg_shots[-train_ind, ]

comp_agg_shots <- filter(agg_shots, Player_Name == c('kobe bryant', 'lebron james', 'stephen curry', 'kyrie irving', 'anthony davis', 'russell westbrook', 'deandre jordan'))

library(ggplot2)
group <- rep(NA, 829)
group <- ifelse(seq(1, 829) %in% train_ind, "Train", "Test")
df1 <- data.frame(comp_agg_shots$Close_Def_Dist, comp_agg_shots$Touch_Time, group)
df2 <- data.frame(comp_agg_shots$Dribbles, comp_agg_shots$Shot_Clock, group)
df3 <- data.frame(comp_agg_shots$Shot_Distance, comp_agg_shots$Touch_Time, group)
df4 <- data.frame(comp_agg_shots$Shot_Distance, comp_agg_shots$Shot_Clock, group)
df5 <- data.frame(comp_agg_shots$Close_Def_Dist, comp_agg_shots$Dribbles, group)

ggplot(df1, aes(x=Close_Def_Dist, y=Touch_Time, color=group)) + geom_point() + scale_color_discrete(name="") + theme(legend.position = "top")
ggplot(df2, aes(x=Dribbles, y=Shot_Clock, color=group)) + geom_point() + scale_color_discrete(name="") + theme(legend.position = "top")

ggplot(df3, aes(x=Shot_Distance, y=Touch_Time, color=group)) + geom_point() + scale_color_discrete(name="") + theme(legend.position = "top")

ggplot(df4, aes(x=Shot_Distance, y=Shot_Clock, color=group)) + geom_point() + scale_color_discrete(name="") + theme(legend.position = "top")
# Graph indicates that the closer the defender, the less the offensive player holds the ball 
# Could indicate that shooter may not be as accurate since defender is close.

ggplot(df5, aes(x=Close_Def_Dist, y=Dribbles, color=group)) + geom_point() + scale_color_discrete(name="") + theme(legend.position = "top")
# Close defender = less time to dribble. 
# Could play a role in shot selection if shot is on the go, but may not represent for catch-and-shoot.

# PCA
# Run PCA/summary statistic for PC
pr_comp <- prcomp(train, scale. = T)
names(pr_comp)
plot(pr_comp)

# Mean of variables
pr_comp$center

# SD of variables
pr_comp$scale

# Note: Location, Player_Name are insignificant for both mean and SD

pr_comp$rotation

# Finding number of dimensions in matrix x
dim(pr_comp$x)

# Plot of resultant principal components
biplot(pr_comp, scale = 0)
```

PVE
std_dev <- pr_comp$sdev

# Calculate variance to identify which component has highest variance
pr_comp_var <- std_dev ^2
pr_comp_var

# Proportion of variance explained
pr_var_ex <- pr_comp_var/sum(pr_comp_var)
pr_var_ex
#22.4% of variance is explained by PC1, 20.4% of variance is explained by PC2, etc.

# Determine which components to keep via scree plot
plot(pr_var_ex, xlab = 'Principal Component', ylab = 'Proportion of Variance Explained', type = 'b')

# Plot cummulative scree plot
plot(cumsum(pr_var_ex), xlab = 'Principal Component', ylab = 'Proportion of Variance Explained', type = 'b')

# It seems that we can keep at 13 PCs even though the last 2-3 plateau around 98%. 
# This is probably due to the fact that location and player_name were converted from categorical data.

# Decision Tree

library(tree)
library(ISLR)
attach(comp_agg_shots)
head(comp_agg_shots)

comp_agg_shots1 <- data.frame(Location=comp_agg_shots[,1], Shot_Number=comp_agg_shots[,2], Period=comp_agg_shots[,3], Shot_Clock=comp_agg_shots[,4], Dribbles=comp_agg_shots[,5], Touch_Time=comp_agg_shots[,5], Shot_Distance=comp_agg_shots[,7], Pts_Type=comp_agg_shots[,8], Shot_Result=comp_agg_shots[,9], Close_Def_Dist=comp_agg_shots[,10])

Factors = comp_agg_shots[, c('Shot_Number', 'Period', 'Shot_Clock', 'Dribbles', 'Touch_Time',  'Shot_Distance', 'Pts_Type', 'Close_Def_Dist')]
Result = comp_agg_shots[, 'Shot_Result']

# Setting up first tree
shot.tree1 = tree(Shot_Result~., data = comp_agg_shots1, subset = train_ind)
summary(shot.tree1)
plot(shot.tree1)
text(shot.tree1, pretty=0)

# Decision Tree and Table for Small Tree
shot.tree.pred1 = predict(shot.tree1, comp_agg_shots1[-train_ind,], type = "class")
Shot_test <- comp_agg_shots$Shot_Result[-train_ind]
# Error for Small Tree

error1 = table(shot.tree.pred1, Shot_test)
# Accuracy
sum(diag(error1))/sum(error1) #62.0%
# Train Error Rate
1-sum(diag(error1))/sum(error1) #38.0%

# Setup for large tree
setup1 = tree.control(nrow(train), mincut = 5, minsize = 10, mindev=0.001)

# Setting up tree 2
shot.tree2 = tree(Shot_Result~., data = comp_agg_shots1[-train_ind,], subset = train_ind, control = setup1)
summary(shot.tree2)
plot(shot.tree2)
text(shot.tree2, pretty=0)

# Decision Tree and Table for large tree
shot.tree.pred2 = predict(shot.tree2, comp_agg_shots1[-train_ind,], type="class")

Shot_test <- comp_agg_shots$Shot_Result[-train_ind]

# Training error for large tree
error2 = table(shot.tree.pred2, Shot_test)
# Accuracy
sum(diag(error2))/sum(error2) #75.6%
# Train Error Rate
1-sum(diag(error2))/sum(error2) #24.0%

# Finding optimal tree
set.seed(5)
cv.shot = cv.tree(shot.tree2, FUN=prune.misclass)
cv.shot
summary(cv.shot)
# Size = 3

prune.shot = prune.misclass(shot.tree1, best = 3)
plot(prune.shot)
text(prune.shot, pretty=0)

# Train error for pruned tree
tree.pred = predict(prune.shot, comp_agg_shots1[-train_ind,], type="class")
error3 = table(tree.pred, Shot_test)
summary(tree.pred)

# Accuracy
sum(diag(error3))/sum(error3) #62.0%
# Train Error
1-sum(diag(error3))/sum(error3) #38.0%
# To be expected because the tree generalizes missed and made shots on essentially two factors when players can still miss when close to the rim

# Random Forest

library(randomForest)
set.seed(1)
bag.shot = randomForest(Shot_Result~., data = comp_agg_shots1[-train_ind,], subset=train_ind, mtry=8, importance = TRUE, ntree = 1000, na.action=na.exclude)
bag.shot

# Train error
tree.pred=predict(bag.shot, comp_agg_shots1[-train_ind,], type="class")
table(tree.pred, Shot_test)

(14+9)/nrow(test)

importance(bag.shot)
varImpPlot((bag.shot))
# Seems that shot distance and shot clock played the biggest factors in determining whether or not the shot went in

# KNN for finding optimal K

library(ISLR)
library(plyr)
library(dplyr)
library(class)

XTrain = train[, c('Shot_Number', 'Period', 'Shot_Clock', 'Dribbles', 'Touch_Time',  'Shot_Distance', 'Pts_Type', 'Close_Def_Dist')]
YTrain = train[, 'Shot_Result']

XTest = test[, c('Shot_Number', 'Period', 'Shot_Clock', 'Dribbles', 'Touch_Time',  'Shot_Distance', 'Pts_Type', 'Close_Def_Dist')]
YTest = test[, 'Shot_Result']

# Predict train set for k=5
pred.YTrain = knn(XTrain, XTrain, YTrain, k=5)
train$pred5 = pred.YTrain
conf.matrix5 = table(pred.YTrain, YTrain)

# Accuracy
sum(diag(conf.matrix5)/sum(conf.matrix5)) #71.3%
# Train Error
1-sum(diag(conf.matrix5)/sum(conf.matrix5)) #28.7%

# Predict train error for k=55
pred.YTrain = knn(XTrain, XTrain, YTrain, k=55)
train$pred55 = pred.YTrain
conf.matrix55 = table(pred.YTrain, YTrain)

# Accuracy
sum(diag(conf.matrix5)/sum(conf.matrix55)) #63.6%
# Train Error
1-sum(diag(conf.matrix5)/sum(conf.matrix55)) #36.4%

# Predict test error for k=5
pred.YTest = knn(XTest, XTest, YTest, k=5)
test$pred5 = pred.YTest
conf.matrixtest5 = table(pred.YTest, YTest)

# Accuracy
sum(diag(conf.matrixtest5)/sum(conf.matrixtest5)) #77.4%
# Test Error
1-sum(diag(conf.matrixtest5)/sum(conf.matrixtest5)) #22.5%

# Predict test error for k=55
pred.YTest = knn(XTest, XTest, YTest, k=55)
test$pred55 = pred.YTest
conf.matrixtest55 = table(pred.YTest, YTest)

# Accuracy
sum(diag(conf.matrixtest55)/sum(conf.matrixtest55)) #62.98%
# Test Error
1-sum(diag(conf.matrixtest55)/sum(conf.matrixtest55)) #37.0%

# Choosing optimal K for test
train.error.rate = NULL
test.error.rate = NULL

knn.wrap1 <- function(k, YTest){
  pred.YTest = knn.cv(XTest, YTest, k=k)
  mean(YTest != pred.YTest)
}

test.error.rate = sapply(1:50, knn.wrap1, YTest = YTest)

test.error.rate #best k is 5 at 0.3461
knnTest1 <- knn.cv(XTest, YTest, 5)
mean(knnTest1 != YTest) #0.3461 

conf.matrixtestk = table(knnTest1, YTest)

# Accuracy
sum(diag(conf.matrixtestk)/sum(conf.matrixtestk)) #65.38%
# Test Error
1-sum(diag(conf.matrixtestk)/sum(conf.matrixtestk)) #34.6%

# Optimal K value for train
knn.wrap2 <- function(k, YTrain){
  pred.YTrain = knn.cv(XTrain, YTrain, k=k)
  mean(YTrain != pred.YTrain)
}

train.error.rate = sapply(1:50, knn.wrap2, YTrain)
train.error.rate #best k is at 43
knnTest2 <- knn.cv(XTrain, YTrain, 43)
mean(knnTest2 != YTrain) #0.372

conf.matrixtraink = table(knnTest2, YTrain)

# Accuracy
sum(diag(conf.matrixtraink)/sum(conf.matrixtraink)) #62.8%
# Test Error
1-sum(diag(conf.matrixtraink)/sum(conf.matrixtraink)) #37.2%

# SVM

library(e1071)
library(MASS)

comp_agg_shots[is.na(comp_agg_shots)] <- 0

model <- svm(Shot_Result~., data = comp_agg_shots, kernel="linear", cost=10, scale = TRUE)
print(model)
summary(model)

set.seed(4)
plot(model, comp_agg_shots, Close_Def_Dist~Dribbles)
plot(model, comp_agg_shots, Shot_Clock~Shot_Distance)
plot(model, comp_agg_shots, Touch_Time~Shot_Distance)

shot_svm_pred <- predict(model, comp_agg_shots)
svm_table = table(shot_svm_pred, comp_agg_shots$Shot_Result)
svm_table

# Accuracy
sum(diag(svm_table)/sum(svm_table))

# Test Error
1-sum(diag(svm_table)/sum(svm_table))

# LDA

library(MASS)
require(gridExtra)

set.seed(2)
shots.lda <- lda(Shot_Result ~., data = test, subset = train_ind)

shots.hat <- predict(shots.lda, test)
lda_test1 <- comp_agg_shots$Shot_Result[-train_ind]
tab_hats <- table(lda_test1, shots.hat$class)
tab_hats

# Accuracy
sum(diag(tab_hats)/sum(tab_hats)) #77.4%

# Test error for lda1
1-sum(diag(tab_hats)/sum(tab_hats)) #22.6%

# QDA

set.seed(2)
shots.qda = qda(Shot_Result ~., data = test, subset = train_ind)

shots.hat2 = predict(shots.qda, test)
qda_test1 <- comp_agg_shots$Shot_Result[-train_ind]

tab_hats2 <- table(qda_test1, shots.hat$class)
tab_hats2

# Accuracy
sum(diag(tab_hats2)/sum(tab_hats2)) #77.4%

# Test error for lda1
1-sum(diag(tab_hats2)/sum(tab_hats2)) #22.6
```




